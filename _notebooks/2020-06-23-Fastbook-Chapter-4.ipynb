{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai2.vision.all import *\n",
    "from utils import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fast.ai Chapter 4\n",
    "\n",
    "# Further research questions\n",
    "\n",
    "## First research question\n",
    "\n",
    "> Create your own implementation of `Learner` from scratch, based on the training loop shown in this chapter.\n",
    "\n",
    "The learner takes the following inputs:\n",
    "\n",
    "- DataLoaders\n",
    "- the model \n",
    "- the optimization function \n",
    "- the loss function\n",
    "- optionally any metrics to print\n",
    "\n",
    "I'll recreate the `fast.ai` `Learner` by using the data from the chapter: identifying 3's from 7's.\n",
    "\n",
    "### Create the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read each image and then convert it to a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the pixels by dividing them by 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = valid_7_tens.float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then put all of the training images on a rank 2 tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the labels, we put them in a column vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we put both of these tensors in the dataLoaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "dl = DataLoader(dset, batch_size=256)\n",
    "\n",
    "valid_dset = list(zip(valid_x,valid_y))\n",
    "valid_dl = DataLoader(valid_dset, batch_size=256)\n",
    "\n",
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "\n",
    "Remember: a neural network is just a composition of a linear function and some activation function: many times over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the optimization function\n",
    "\n",
    "`fastai` already comes with its own `SGD` optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function fastai2.optimizer.SGD(params, lr, mom=0.0, wd=0.0, decouple_wd=True)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "`pytorch` already has an implementation of the cross entropy loss function that we use in binary classification problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics to print\n",
    "\n",
    "We will print the accuracy on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together in the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    \n",
    "    def __init__(self, dataloaders, model, opt, loss):\n",
    "        \n",
    "        self.train_dl = dataloaders[0]\n",
    "        self.valid_dl = dataloaders[1]\n",
    "        self.model = model\n",
    "        self.opt = opt(self.model.parameters(), lr=0.1)\n",
    "        self.loss = loss\n",
    "        \n",
    "    def batch_accuracy(self, preds, yb):\n",
    "        \n",
    "        correct = (preds>0.5) == yb\n",
    "        return correct.float().mean()\n",
    "        \n",
    "    def validate_epoch(self):\n",
    "        \n",
    "        accs = [self.batch_accuracy(self.model(xb), yb) for xb,yb in self.valid_dl]\n",
    "        return round(torch.stack(accs).mean().item(), 4)\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        \n",
    "        for xb,yb in self.train_dl:\n",
    "            preds = self.model(xb)\n",
    "            calculated_loss = self.loss(preds, yb*1.0)\n",
    "            calculated_loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "                \n",
    "    def fit(self, n):\n",
    "        \n",
    "        for epoch in range(n):\n",
    "            self.train_epoch()\n",
    "            print(self.validate_epoch(), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking our learner for a spin\n",
    "\n",
    "We can train test our learner on the data for 3's and 7's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5068 0.7793 0.9033 0.9297 0.9434 0.9516 0.9565 0.9599 0.9653 0.9658 0.9658 0.9678 0.9687 0.9692 0.9697 0.9707 0.9721 0.9726 0.9731 0.9736 0.9741 0.9746 0.9741 0.9746 0.9751 0.9756 0.9761 0.9765 0.977 0.9765 0.9775 0.978 0.978 0.978 0.978 0.978 0.978 0.979 0.9795 0.9799 "
     ]
    }
   ],
   "source": [
    "example = Learner(dls, simple_net, SGD, nn.BCELoss())\n",
    "example.fit(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Research Question\n",
    "\n",
    "> Complete all the steps in this chapter using the full MNIST datasets (that is, for all digits, not just 3s and 7s). This is a significant project and will take you quite a bit of time to complete! You'll need to do some of your own research to figure out how to overcome some obstacles you'll meet on the way.\n",
    "\n",
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('C:/Users/57319/.fastai/data/mnist_png/testing'),Path('C:/Users/57319/.fastai/data/mnist_png/training')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `DataBlock` API to read both the train and test folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = DataBlock(blocks=(ImageBlock(cls=PILImageBW), CategoryBlock), \n",
    "                  get_items=get_image_files, \n",
    "                  splitter=GrandparentSplitter(train_name='training', valid_name='testing'),\n",
    "                  get_y=parent_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mnist.dataloaders(path, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=9, figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must modify our sequential model to first *flatten* the 28x28 images that we just loaded. Also, we **must output in the final layer 10 activations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we must **change our loss function and our definition of accuracy now that we have a multi-class problem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    \n",
    "    def __init__(self, dataloaders, model, opt, loss):\n",
    "        \n",
    "        self.train_dl = dataloaders[0]\n",
    "        self.valid_dl = dataloaders[1]\n",
    "        self.model = model\n",
    "        self.opt = opt(self.model.parameters(), lr=0.1)\n",
    "        self.loss = loss\n",
    "        \n",
    "    def train_epoch(self):\n",
    "                \n",
    "        for xb,yb in self.train_dl:\n",
    "            preds = self.model(xb)\n",
    "            calculated_loss = self.loss(preds, yb.long())\n",
    "            calculated_loss.backward()\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "            \n",
    "            \n",
    "    def batch_accuracy(self, preds, yb):\n",
    "        \n",
    "        probs = torch.softmax(preds, dim=1)\n",
    "        winners = probs.argmax(dim=1)\n",
    "        corrects = (winners == yb)\n",
    "        accuracy = corrects.sum().float() / float( yb.size(0) )\n",
    "        return accuracy\n",
    "\n",
    "        \n",
    "    def validate_epoch(self):\n",
    "        \n",
    "        accs = [self.batch_accuracy(self.model(xb), yb) for xb,yb in self.valid_dl]\n",
    "        return round(torch.stack(accs).mean().item(), 4)\n",
    "                            \n",
    "    def fit(self, n):\n",
    "        \n",
    "        for epoch in range(n):\n",
    "            self.train_epoch()\n",
    "            print(self.validate_epoch(), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9179 0.9398 0.9487 0.9538 0.9584 0.9602 0.9606 0.9635 0.9645 0.9664 "
     ]
    }
   ],
   "source": [
    "mnist_learner = Learner(dls, simple_net.to(device), SGD, nn.CrossEntropyLoss())\n",
    "mnist_learner.fit(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96% accuracy! not that bad for such a simple model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
